---
layout: post
title:  "Mapping Acoustic Evolution: A Data Dive into 1969 vs. 2019 Billboard Hot 100 Hits"
date: 2025-02-02
description: "Using APIs to look at 1969 and 2019 Billboard hits reveals a stark acoustic evolution—from raw guitar solos to algorithm-friendly synth drops—in this data-driven analysis of these musical eras."
image: "/assets/img/music_title.jpg"
---

## The Big Question
If you asked your parents for their taste in music, how would you say it differs from your own? What about if you asked your grandparents? In this analysis we look at data from both 1969 and 2019 to see how our music taste has changed throughout the decades.

**Prerequisites:** this post implies beginner/intermidiate level experience in python, as well as a basic knowledge of how web scraping/APIs work. We will skip over a lot of the technicalities of certain functionality within Python in order to provide a more generalized tutorial. Note that the full extent of the code will be available in <a href="$#%#$%#$%#$%$" target="_blank">this GitHub repo</a> and in <a href="https://colab.research.google.com/drive/1phtDM0d5QpX2lh2Ned37iKutmkBE41dj?usp=sharing" target="_blank">this Google Colab notebook</a> as well.

**Learning Goals**

- The basics of API usage (particularly the MusicBrainz and AcousticBrainz APIs)
- How the most popular songs' acoustic features have changed since 1969

## What are people listening to?

To perform an analysis, we first need our data. For this we will be using first <a href="https://github.com/mhollingshead/billboard-hot-100/tree/main" target="_blank">This Github Repository</a>, which contains a dataset of the historic Billboard Hot 100 tracks since 1958. 

After loading in the dataset, we then filter the data to only select the songs of 1969 as well as 2019, saving each dataframe as csv files for later use. Note that we do not remove duplicates in this analysis, as we assume that a song being repeated on the Billboard Hot 100 is indicative of its popularity and enduring appeal.

Let's pick and compare the first two songs in each dataframe:

```python
print(f"2019: {billboard_df_2019['song'][0]} by {billboard_df_2019['artist'][0]}\n"
      f"1969: {billboard_df_1969['song'][0]} by {billboard_df_1969['artist'][0]}")
```

`output:` 

`2019: Thank U, Next by Ariana Grande`

`1969: I Heard It Through The Grapevine by Marvin Gaye`

Ah yes, one talking about their ex and the other of hearing rumors through the grapevine. Truly, the Billboard Hot 100 has always been the ultimate melting pot of everything gossip related!

## Using the MusicBrainz API

Now that we have our songs to analyze, we must uncover the acoustic features of each one. To do this, we will use a website called AcousticBrainz, which functions best when provided with a specific song ID (called an MBID). But first, we need to extract each song's MBID. Think of an MBID as a unique fingerprint for every song. With this fingerprint, we can then find then specific details pertaining to this individual song. To get these IDs, we will use a different website called MusicBrainz. All we need to get started with using the API is the base url which I have provided, a 'query' which is essentially how we will look up each song, and our 'User-Agent' which is essentially identifying ourself to the website. Website owners like to know who is using their data.

**Note:** It is important to always review API documentation, find the documentation for the MusicBrainz API <a href="https://musicbrainz.org/doc/Beginners_Guide" target="_blank">here</a>. Every API is different and had different syntax, requirements, and limitations.

First, we define a function to extract the MBID of any individual song.

```python
def get_recording_mbid(song, artist):
    # define our base url
    url = "https://musicbrainz.org/ws/2/recording"

    # query is what will be searched
    query = f'"{song}" by "{artist}"'

    params = {
        'query': query,
        'fmt': 'json',
        'limit': 1 # limit 1 indicates that we only want the first entry
        }

    headers = {
        # here you put the name of your application/purpose of API usage
        # as well as your email to identify who you are
        'User-Agent': 'DataAnalysis/1.0 (youremail@exampledomain.com)' 
        }
    
    try:
        response = requests.get( #get the data!!!
            url,
            params=params,
            headers=headers
            )
        # here we normalize our json output, selecting only the recording part of the multi-nested list, 
        # selecting the first element of the first list and only the 'id', this will give us the MBID
        return pd.json_normalize(response.json())['recordings'][0][0]['id']
    
    except: # in the case of an error, put a null value in the cell
        return None
```

Lets see how it works! `get_recording_mbid(billboard_df_2019['song'][0], billboard_df_2019['artist'][0])` gives us the MBID for "Thank U, Next" and outputs `274b3a7b-64bd-4af3-9af9-dd41277ddc17`.

With the function working, we can create a for loop to extract the MBID of every individual song in both dataframes.

**Note: ** the MusicBrainz API has a rate limit of 10 requests per every 10 seconds, in our code we use a sleep timer of 1.5 just to be safe. Remember to not exceed the rate limit or you will be banned temporarily (or even permanently).

## Extracting Song Features

Finally, we can start extracting the acoustic features of each individual song using the AcousticBrainz API. We define a function called `get_song_features`. While this is a lengthy function, the most important part to understand is that we take an MBID as our input, and we fetch the features based on their level using separate links. Low level features are more unambiguous such as key signature, BPM, while high level features are more up for interpretation. These could be things such as dancability, energy, or loudness. These features are being computed by a separate algorithm that can be found <a href="https://essentia.upf.edu" target="_blank">here</a>. Check the details for all AcousticBrainz features and for API documentation <a href="https://acousticbrainz.org/data" target="_blank">here</a>.

Let's check out the features for Mariah Carrey's 'All I Want For Christmas Is You':

```python
get_song_features(billboard_df_2019['mbid'][2])
```

`output: {'danceability': 'danceable', 'genre': 'pop', `
          `'gender': 'female', 'mood': 'not_aggressive', `
          `'instrumental': 'voice', 'bpm': 150.164459229, `
          `'key': 'G', 'loudness': 0.871298909187, `
          `'mood_happy': 'happy'}`

It seems fairly accurate, although I don't remember the song being particularly loud.

After defining the function, we need to loop through each data frame in order to retrieve the features of each song. What we need to do essentially is loop through the dataframe, running the `get_song_features` function to extract each row's features. Then, we assign each row's respective features to the corresponding column. An optimized version of this loop is included in the code.

Now we can save the results and analyze the data!

**Note:** In the GitHub repository is the complete data that we retrieved from running this code.

## The Big Picture

First lets look at what we have to deal with:

```python
print(f"Number of songs from 1969: {len(billboard_df_1969)}")
print(f"Number of songs from 2019: {len(billboard_df_2019)}")
```

`output:`

`Number of songs from 1969: 2248`

`Number of songs from 2019: 2547`

Not too shabby, we were able to retrieve the features for about half of the songs. 

## Are We Going Deaf?

Have your parents ever told you that the music you listen to is too loud? Let's compare and see if we really are dealing serious damage to our eardrums.

```python
print(f"Mean loudness coefficient in 1969: {billboard_df_1969['loudness'].mean()}")
print(f"Mean loudness coefficient in 2019: {billboard_df_2019['loudness'].mean()}")
```

`output:`

`Mean loudness coefficient in 1969: 0.7608138030109645`

`Mean loudness coefficient in 2019: 0.8266435674148748`

Well, it has increased. I am not quite sure what this means for the future of our ears, however. More on the loudness feature's interpretability <a href="https://essentia.upf.edu/reference/streaming_Loudness.html" target="_blank">here</a>.

## From Mood Swings to Who's Causing Them

We extracted a feature called mood_happy. Essentially this will tell us if the algorithm classified the song as a 'happy' tune or a 'not happy' one (not exactly sure what fits under the not happy category). Plotting the proportion of both years' moods gives us the following bar plot:

<figure>
	<img src="{{site.url}}/{{site.baseurl}}/assets/img/happy_proportion.png" alt=""> 
	<figcaption>Figure 1. - Happiness</figcaption>
</figure>

The proportion of happy songs has taken quite the nosedive. I guess heartbreak wasn’t trending in 1969 like it seems to be now.

Let's take a look at the proportion of artists recognized by the algorithm as 'male' or 'female'.

<figure>
	<img src="{{site.url}}/{{site.baseurl}}/assets/img/gender_proportion.png" alt=""> 
	<figcaption>Figure 2. - Gender</figcaption>
</figure>

Cool! These would be interesting topics to explore further.

## One-Hit Wonders: Then vs. Now

We conclude by looking at the longevity of songs on the Billboard Hot 100. Here we are taking unique songs that have been in the #1-5 position and looking at the maximum number of weeks they were on the chart.

<figure>
	<img src="{{site.url}}/{{site.baseurl}}/assets/img/weeks_on_chart_top5_max.png" alt=""> 
	<figcaption>Figure 3. - Weeks on Chart</figcaption>
</figure>

It seems to me like songs seem to last longer on the Billboard Hot 100 in the current day. I would imagine there are a number of factors that have contributed to this.

## What's Next?

Before concluding with this post, here are some ideas to help spark some curiosity:

- How do certain features (mood, dancability, etc.) differ between months in each year?
- What similarities between genres are seen between the two years? How do they differ?
- How do the number of unique artists in the top 5 compare between 1969 and 2019? Is there more diversity in recent years?
- What is the relationship between a song's peak position and its total weeks_on_chart?

## Conclusion and Final Thoughts

In this post we learned the basics of API usage, and learned about how songs have changed throughout the decades. Now go and experiment with the APIs we have reviewed or other ones you may find!

For other resources, see below:

- Discover how to use the essentia open-source library for more audio analysis in python <a href="https://essentia.upf.edu/essentia_python_tutorial.html" target="_blank">here</a>.
- Learn advanced EDA with <a href="https://seaborn.pydata.org/tutorial.html" target="_blank">Seaborn Tutorials</a>

**Found this helpful?** Share it with a friend or <a href="https://twitter.com/intent/tweet?text=Check%20out%20this%20awesome%20python%20tutorial!%20https://ericanti.github.io/my-blog/blog/api-usage/" target="_blank">tweet about it</a>!

---

<a href="^&$*#&^$" target="_blank">Link to GitHub repository</a>